# AI Server Environment Variables Configuration
# Copy this file to .env and fill in your actual values
# NEVER commit the .env file to version control

# ================================
# Hugging Face Configuration (Required)
# ================================
# Get your token from: https://huggingface.co/settings/tokens
# This is required for downloading and using Hugging Face models
HF_TOKEN=your_hugging_face_token_here

# ================================
# Server Configuration
# ================================
# Host for the AI server (default: 0.0.0.0 for all interfaces)
HOST=0.0.0.0

# Port for the AI server (default: 8000)
PORT=8000

# ================================
# Model Configuration
# ================================
# Hugging Face model to use (default: microsoft/DialoGPT-medium)
MODEL_NAME=microsoft/DialoGPT-medium

# Maximum tokens to generate (default: 100)
MAX_TOKENS=100

# Temperature for text generation (0.0 to 1.0, default: 0.7)
TEMPERATURE=0.7

# ================================
# Performance Configuration
# ================================
# Device to use for inference (cpu, cuda, auto)
DEVICE=auto

# Maximum batch size for processing
MAX_BATCH_SIZE=4

# ================================
# Logging Configuration
# ================================
# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ================================
# Example Values (DO NOT USE IN PRODUCTION)
# ================================
# HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# HOST=0.0.0.0
# PORT=8000
# MODEL_NAME=microsoft/DialoGPT-medium
# MAX_TOKENS=100
# TEMPERATURE=0.7